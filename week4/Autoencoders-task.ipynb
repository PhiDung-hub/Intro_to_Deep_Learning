{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "192px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "Autoencoders-task.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH2l5wVZ1x3O"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-AoYEZe1x3Q"
      },
      "source": [
        "# Denoising Autoencoders And Where To Find Them\n",
        "\n",
        "Today we're going to train deep autoencoders and apply them to faces and similar images search.\n",
        "\n",
        "Our new test subjects are human faces from the [lfw dataset](http://vis-www.cs.umass.edu/lfw/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW0kEdx_1x3Q"
      },
      "source": [
        "# Import stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIsiuWfeEs-e",
        "outputId": "f3e92472-eea6-4bfd-a0f2-67195dfb5bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "setup_google_colab.setup_week4()\n",
        "# setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2021-06-08 14:58:00--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-08 14:58:00 (55.4 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n",
            "**************************************************\n",
            "lfw-deepfunneled.tgz\n",
            "**************************************************\n",
            "lfw.tgz\n",
            "**************************************************\n",
            "lfw_attributes.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:38:45.815533Z",
          "start_time": "2018-01-04T16:38:45.767828Z"
        },
        "collapsed": true,
        "id": "2ggZD6ug1x3Q"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import grading"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:38:56.825485Z",
          "start_time": "2018-01-04T16:38:46.131894Z"
        },
        "collapsed": true,
        "id": "qeagWycV1x3R",
        "outputId": "c991a559-0210-4e4d-bcc7-e8decc5a6669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers as L, backend as K\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lfw_dataset import load_lfw_dataset\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import download_utils\n",
        "import keras_utils\n",
        "import numpy as np\n",
        "from keras_utils import reset_tf_session"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dc162d7cc3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreset_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/keras_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize_keras_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# note: topology.Node is an internal class,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# it isn't meant to be used by Keras users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mask_to_proceed_with_overwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_summary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# using their correct version.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0mpopulate_deserializable_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mpopulate_deserializable_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mv2_objs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mbase_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mv2_objs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0minitializers_v2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:38:56.830804Z",
          "start_time": "2018-01-04T16:38:56.827147Z"
        },
        "id": "Wqq-CgHb1x3R"
      },
      "source": [
        "# !!! remember to clear session/graph if you rebuild your graph to avoid out-of-memory errors !!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoKABS-V1x3R"
      },
      "source": [
        "# Load dataset\n",
        "Dataset was downloaded for you. Relevant links (just in case):\n",
        "- http://www.cs.columbia.edu/CAVE/databases/pubfig/download/lfw_attributes.txt\n",
        "- http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\n",
        "- http://vis-www.cs.umass.edu/lfw/lfw.tgz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:38:56.917476Z",
          "start_time": "2018-01-04T16:38:56.832132Z"
        },
        "collapsed": true,
        "id": "-RYcNouh1x3R"
      },
      "source": [
        "# we downloaded them for you, just link them here\n",
        "download_utils.link_week_4_resources()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:39:21.680162Z",
          "start_time": "2018-01-04T16:39:01.554782Z"
        },
        "collapsed": true,
        "id": "zN61oKYa1x3S",
        "outputId": "15bd288c-5e59-477d-d7d7-843d00939dfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load images\n",
        "X, attr = load_lfw_dataset(use_raw=True, dimx=32, dimy=32)\n",
        "IMG_SHAPE = X.shape[1:]\n",
        "\n",
        "# center images\n",
        "X = X.astype('float32') / 255.0 - 0.5\n",
        "\n",
        "# split\n",
        "X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:39:36.649891Z",
          "start_time": "2018-01-04T16:39:36.646605Z"
        },
        "collapsed": true,
        "id": "gxFP7EAW1x3S"
      },
      "source": [
        "def show_image(x):\n",
        "  plt.imshow(np.clip(x + 0.5, 0, 1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:39:39.028360Z",
          "start_time": "2018-01-04T16:39:38.258425Z"
        },
        "collapsed": true,
        "id": "ryJ_1i0E1x3S",
        "outputId": "d385279d-759d-489a-87b8-49a1d490f387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "plt.title('sample images')\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    show_image(X[i])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"attr shape:\", attr.shape)\n",
        "\n",
        "# try to free memory\n",
        "del X\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (13143, 32, 32, 3)\n",
            "attr shape: (13143, 73)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5frtCiJ91x3S"
      },
      "source": [
        "# Autoencoder architecture\n",
        "\n",
        "Let's design autoencoder as two sequential keras models: the encoder and decoder respectively.\n",
        "\n",
        "We will then use symbolic API to apply and train these models.\n",
        "\n",
        "<img src=\"https://github.com/PhiDung-hub/intro-to-dl/blob/master/week4/images/autoencoder.png?raw=1\" style=\"width:50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5112QLkF1x3S"
      },
      "source": [
        "# First step: PCA\n",
        "\n",
        "Principial Component Analysis is a popular dimensionality reduction method. \n",
        "\n",
        "Under the hood, PCA attempts to decompose object-feature matrix $X$ into two smaller matrices: $W$ and $\\hat W$ minimizing _mean squared error_:\n",
        "\n",
        "$$\\|(X W) \\hat{W} - X\\|^2_2 \\to_{W, \\hat{W}} \\min$$\n",
        "- $X \\in \\mathbb{R}^{n \\times m}$ - object matrix (**centered**);\n",
        "- $W \\in \\mathbb{R}^{m \\times d}$ - matrix of direct transformation;\n",
        "- $\\hat{W} \\in \\mathbb{R}^{d \\times m}$ - matrix of reverse transformation;\n",
        "- $n$ samples, $m$ original dimensions and $d$ target dimensions;\n",
        "\n",
        "In geometric terms, we want to find d axes along which most of variance occurs. The \"natural\" axes, if you wish.\n",
        "\n",
        "<img src=\"https://github.com/PhiDung-hub/intro-to-dl/blob/master/week4/images/pca.png?raw=1\" style=\"width:30%\">\n",
        "\n",
        "\n",
        "PCA can also be seen as a special case of an autoencoder.\n",
        "\n",
        "* __Encoder__: X -> Dense(d units) -> code\n",
        "* __Decoder__: code -> Dense(m units) -> X\n",
        "\n",
        "Where Dense is a fully-connected layer with linear activaton:   $f(X) = W \\cdot X + \\vec b $\n",
        "\n",
        "\n",
        "Note: the bias term in those layers is responsible for \"centering\" the matrix i.e. substracting mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:39:42.058684Z",
          "start_time": "2018-01-04T16:39:42.046303Z"
        },
        "collapsed": true,
        "id": "cB_1sIvW1x3T"
      },
      "source": [
        "def build_pca_autoencoder(img_shape, code_size):\n",
        "    \"\"\"\n",
        "    Here we define a simple linear autoencoder as described above.\n",
        "    We also flatten and un-flatten data to be compatible with image shapes\n",
        "    \"\"\"\n",
        "    \n",
        "    encoder = keras.models.Sequential()\n",
        "    encoder.add(L.InputLayer(img_shape))\n",
        "    encoder.add(L.Flatten())                  #flatten image to vector\n",
        "    encoder.add(L.Dense(code_size))           #actual encoder\n",
        "\n",
        "    decoder = keras.models.Sequential()\n",
        "    decoder.add(L.InputLayer((code_size,)))\n",
        "    decoder.add(L.Dense(np.prod(img_shape)))  #actual decoder, height*width*3 units\n",
        "    decoder.add(L.Reshape(img_shape))         #un-flatten\n",
        "    \n",
        "    return encoder,decoder"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SthFkSB1x3U"
      },
      "source": [
        "Meld them together into one model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:41:04.366409Z",
          "start_time": "2018-01-04T16:40:45.919042Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "OVOHBKLo1x3U",
        "outputId": "ee13d42d-69e6-4b0d-c2a5-3b073210d397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "s = reset_tf_session()\n",
        "\n",
        "encoder, decoder = build_pca_autoencoder(IMG_SHAPE, code_size=32)\n",
        "\n",
        "inp = L.Input(IMG_SHAPE)\n",
        "code = encoder(inp)\n",
        "reconstruction = decoder(code)\n",
        "\n",
        "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
        "autoencoder.compile(optimizer='adamax', loss='mse')\n",
        "\n",
        "autoencoder.fit(x=X_train, y=X_train, epochs=15,\n",
        "                validation_data=[X_test, X_test],\n",
        "                callbacks=[keras_utils.TqdmProgressCallback()],\n",
        "                verbose=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "\n",
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3f2d5bc2809b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTqdmProgressCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 verbose=0)\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n",
            "\u001b[0;32m/content/keras_utils.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook_failsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values_by_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tqdm_utils.py\u001b[0m in \u001b[0;36mtqdm_notebook_failsafe\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_simple_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# tqdm is broken on Google Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSimpleTqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tqdm_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, total, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:41:11.747674Z",
          "start_time": "2018-01-04T16:41:11.730725Z"
        },
        "collapsed": true,
        "id": "WUyX7oS71x3U"
      },
      "source": [
        "def visualize(img,encoder,decoder):\n",
        "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
        "    code = encoder.predict(img[None])[0]  # img[None] is the same as img[np.newaxis, :]\n",
        "    reco = decoder.predict(code[None])[0]\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title(\"Original\")\n",
        "    show_image(img)\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title(\"Code\")\n",
        "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title(\"Reconstructed\")\n",
        "    show_image(reco)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:41:18.700138Z",
          "start_time": "2018-01-04T16:41:17.026047Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "RYg4uhX_1x3V"
      },
      "source": [
        "score = autoencoder.evaluate(X_test,X_test,verbose=0)\n",
        "print(\"PCA MSE:\", score)\n",
        "\n",
        "for i in range(5):\n",
        "    img = X_test[i]\n",
        "    visualize(img,encoder,decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKlLR59a1x3V"
      },
      "source": [
        "# Going deeper: convolutional autoencoder\n",
        "\n",
        "PCA is neat but surely we can do better. This time we want you to build a deep convolutional autoencoder by... stacking more layers.\n",
        "\n",
        "## Encoder\n",
        "\n",
        "The **encoder** part is pretty standard, we stack convolutional and pooling layers and finish with a dense layer to get the representation of desirable size (`code_size`).\n",
        "\n",
        "We recommend to use `activation='elu'` for all convolutional and dense layers.\n",
        "\n",
        "We recommend to repeat (conv, pool) 4 times with kernel size (3, 3), `padding='same'` and the following numbers of output channels: `32, 64, 128, 256`.\n",
        "\n",
        "Remember to flatten (`L.Flatten()`) output before adding the last dense layer!\n",
        "\n",
        "## Decoder\n",
        "\n",
        "For **decoder** we will use so-called \"transpose convolution\". \n",
        "\n",
        "Traditional convolutional layer takes a patch of an image and produces a number (patch -> number). In \"transpose convolution\" we want to take a number and produce a patch of an image (number -> patch). We need this layer to \"undo\" convolutions in encoder. We had a glimpse of it during week 3 (watch [this video](https://www.coursera.org/learn/intro-to-deep-learning/lecture/auRqf/a-glimpse-of-other-computer-vision-tasks) starting at 5:41).\n",
        "\n",
        "Here's how \"transpose convolution\" works:\n",
        "<img src=\"https://github.com/PhiDung-hub/intro-to-dl/blob/master/week4/images/transpose_conv.jpg?raw=1\" style=\"width:60%\">\n",
        "In this example we use a stride of 2 to produce 4x4 output, this way we \"undo\" pooling as well. Another way to think about it: we \"undo\" convolution with stride 2 (which is similar to conv + pool).\n",
        "\n",
        "You can add \"transpose convolution\" layer in Keras like this:\n",
        "```python\n",
        "L.Conv2DTranspose(filters=?, kernel_size=(3, 3), strides=2, activation='elu', padding='same')\n",
        "```\n",
        "\n",
        "Our decoder starts with a dense layer to \"undo\" the last layer of encoder. Remember to reshape its output to \"undo\" `L.Flatten()` in encoder.\n",
        "\n",
        "Now we're ready to undo (conv, pool) pairs. For this we need to stack 4 `L.Conv2DTranspose` layers with the following numbers of output channels: `128, 64, 32, 3`. Each of these layers will learn to \"undo\" (conv, pool) pair in encoder. For the last `L.Conv2DTranspose` layer use `activation=None` because that is our final image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:43:33.562406Z",
          "start_time": "2018-01-04T16:43:33.426581Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "oILM5_sa1x3V"
      },
      "source": [
        "# Let's play around with transpose convolution on examples first\n",
        "def test_conv2d_transpose(img_size, filter_size):\n",
        "    print(\"Transpose convolution test for img_size={}, filter_size={}:\".format(img_size, filter_size))\n",
        "    \n",
        "    x = (np.arange(img_size ** 2, dtype=np.float32) + 1).reshape((1, img_size, img_size, 1))\n",
        "    f = (np.ones(filter_size ** 2, dtype=np.float32)).reshape((filter_size, filter_size, 1, 1))\n",
        "\n",
        "    s = reset_tf_session()\n",
        "    \n",
        "    conv = tf.nn.conv2d_transpose(x, f, \n",
        "                                  output_shape=(1, img_size * 2, img_size * 2, 1), \n",
        "                                  strides=[1, 2, 2, 1], \n",
        "                                  padding='SAME')\n",
        "\n",
        "    result = s.run(conv)\n",
        "    print(\"input:\")\n",
        "    print(x[0, :, :, 0])\n",
        "    print(\"filter:\")\n",
        "    print(f[:, :, 0, 0])\n",
        "    print(\"output:\")\n",
        "    print(result[0, :, :, 0])\n",
        "    s.close()\n",
        "        \n",
        "test_conv2d_transpose(img_size=2, filter_size=2)\n",
        "test_conv2d_transpose(img_size=2, filter_size=3)\n",
        "test_conv2d_transpose(img_size=4, filter_size=2)\n",
        "test_conv2d_transpose(img_size=4, filter_size=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:44:43.582011Z",
          "start_time": "2018-01-04T16:44:43.516283Z"
        },
        "collapsed": true,
        "id": "ntyUD5qL1x3W"
      },
      "source": [
        "def build_deep_autoencoder(img_shape, code_size):\n",
        "    \"\"\"PCA's deeper brother. See instructions above. Use `code_size` in layer definitions.\"\"\"\n",
        "    H,W,C = img_shape\n",
        "    \n",
        "    # encoder\n",
        "    encoder = keras.models.Sequential([\n",
        "      L.InputLayer(img_shape),\n",
        "      L.Conv2D(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'),\n",
        "      L.MaxPool2D((3,3)),\n",
        "      L.Conv2D(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'),\n",
        "      L.MaxPool2D((3,3)),\n",
        "      L.Conv2D(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'),\n",
        "      L.MaxPool2D((3,3)),\n",
        "      L.Conv2D(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'),\n",
        "      L.MaxPool2D((3,3)),\n",
        "      L.Flatten(),\n",
        "      L.Dense()\n",
        "    ])\n",
        "    \n",
        "    ### YOUR CODE HERE: define encoder as per instructions above ###\n",
        "\n",
        "    # decoder\n",
        "    decoder = keras.models.Sequential()\n",
        "    decoder.add(L.InputLayer((code_size,)))\n",
        "    decoder.add(L.Conv2DTranspose(filters=?, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
        "    \n",
        "    ### YOUR CODE HERE: define decoder as per instructions above ###\n",
        "    \n",
        "    return encoder, decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:44:53.805124Z",
          "start_time": "2018-01-04T16:44:52.846510Z"
        },
        "collapsed": true,
        "id": "CVbikH9Q1x3W"
      },
      "source": [
        "# Check autoencoder shapes along different code_sizes\n",
        "get_dim = lambda layer: np.prod(layer.output_shape[1:])\n",
        "for code_size in [1,8,32,128,512]:\n",
        "    s = reset_tf_session()\n",
        "    encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=code_size)\n",
        "    print(\"Testing code size %i\" % code_size)\n",
        "    assert encoder.output_shape[1:]==(code_size,),\"encoder must output a code of required size\"\n",
        "    assert decoder.output_shape[1:]==IMG_SHAPE,   \"decoder must output an image of valid shape\"\n",
        "    assert len(encoder.trainable_weights)>=6,     \"encoder must contain at least 3 layers\"\n",
        "    assert len(decoder.trainable_weights)>=6,     \"decoder must contain at least 3 layers\"\n",
        "    \n",
        "    for layer in encoder.layers + decoder.layers:\n",
        "        assert get_dim(layer) >= code_size, \"Encoder layer %s is smaller than bottleneck (%i units)\"%(layer.name,get_dim(layer))\n",
        "\n",
        "print(\"All tests passed!\")\n",
        "s = reset_tf_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:45:16.966538Z",
          "start_time": "2018-01-04T16:45:16.804252Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "wxANTVZP1x3W"
      },
      "source": [
        "# Look at encoder and decoder shapes.\n",
        "# Total number of trainable parameters of encoder and decoder should be close.\n",
        "s = reset_tf_session()\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
        "encoder.summary()\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aqLZRML1x3X"
      },
      "source": [
        "Convolutional autoencoder training. This will take **1 hour**. You're aiming at ~0.0056 validation MSE and ~0.0054 training MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:48:32.365157Z",
          "start_time": "2018-01-04T16:46:03.202875Z"
        },
        "id": "c6_AryfD1x3X"
      },
      "source": [
        "s = reset_tf_session()\n",
        "\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
        "\n",
        "inp = L.Input(IMG_SHAPE)\n",
        "code = encoder(inp)\n",
        "reconstruction = decoder(code)\n",
        "\n",
        "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
        "autoencoder.compile(optimizer=\"adamax\", loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:48:32.365157Z",
          "start_time": "2018-01-04T16:46:03.202875Z"
        },
        "id": "nzJB3X-01x3X"
      },
      "source": [
        "# we will save model checkpoints here to continue training in case of kernel death\n",
        "model_filename = 'autoencoder.{0:03d}.hdf5'\n",
        "last_finished_epoch = None\n",
        "\n",
        "#### uncomment below to continue training from model checkpoint\n",
        "#### fill `last_finished_epoch` with your latest finished epoch\n",
        "# from keras.models import load_model\n",
        "# s = reset_tf_session()\n",
        "# last_finished_epoch = 4\n",
        "# autoencoder = load_model(model_filename.format(last_finished_epoch))\n",
        "# encoder = autoencoder.layers[1]\n",
        "# decoder = autoencoder.layers[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:48:32.365157Z",
          "start_time": "2018-01-04T16:46:03.202875Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "MIy2OoNR1x3X"
      },
      "source": [
        "autoencoder.fit(x=X_train, y=X_train, epochs=25,\n",
        "                validation_data=[X_test, X_test],\n",
        "                callbacks=[keras_utils.ModelSaveCallback(model_filename),\n",
        "                           keras_utils.TqdmProgressCallback()],\n",
        "                verbose=0,\n",
        "                initial_epoch=last_finished_epoch or 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:49:25.084704Z",
          "start_time": "2018-01-04T16:49:23.236568Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "8qLRof8H1x3X"
      },
      "source": [
        "reconstruction_mse = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "print(\"Convolutional autoencoder MSE:\", reconstruction_mse)\n",
        "for i in range(5):\n",
        "    img = X_test[i]\n",
        "    visualize(img,encoder,decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:49:54.273061Z",
          "start_time": "2018-01-04T16:49:54.230656Z"
        },
        "collapsed": true,
        "id": "S_2V6sZl1x3Y"
      },
      "source": [
        "# save trained weights\n",
        "encoder.save_weights(\"encoder.h5\")\n",
        "decoder.save_weights(\"decoder.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:50:01.657093Z",
          "start_time": "2018-01-04T16:50:01.067976Z"
        },
        "collapsed": true,
        "id": "ylNOlrw11x3Y"
      },
      "source": [
        "# restore trained weights\n",
        "s = reset_tf_session()\n",
        "\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
        "encoder.load_weights(\"encoder.h5\")\n",
        "decoder.load_weights(\"decoder.h5\")\n",
        "\n",
        "inp = L.Input(IMG_SHAPE)\n",
        "code = encoder(inp)\n",
        "reconstruction = decoder(code)\n",
        "\n",
        "autoencoder = keras.models.Model(inputs=inp, outputs=reconstruction)\n",
        "autoencoder.compile(optimizer=\"adamax\", loss='mse')\n",
        "\n",
        "print(autoencoder.evaluate(X_test, X_test, verbose=0))\n",
        "print(reconstruction_mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhHwM-5Z1x3Y"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Acl2OvJ51x3Y"
      },
      "source": [
        "from submit import submit_autoencoder\n",
        "submission = build_deep_autoencoder(IMG_SHAPE, code_size=71)\n",
        "\n",
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = ### YOUR TOKEN HERE\n",
        "COURSERA_EMAIL = 'phidung001@e.ntu.edu.sg'\n",
        "\n",
        "submit_autoencoder(submission, reconstruction_mse, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxzmUSBt1x3Y"
      },
      "source": [
        "# Optional: Denoising Autoencoder\n",
        "\n",
        "This part is **optional**, it shows you one useful application of autoencoders: denoising. You can run this code and make sure denoising works :) \n",
        "\n",
        "Let's now turn our model into a denoising autoencoder:\n",
        "<img src=\"https://github.com/PhiDung-hub/intro-to-dl/blob/master/week4/images/denoising.jpg?raw=1\" style=\"width:40%\">\n",
        "\n",
        "We'll keep the model architecture, but change the way it is trained. In particular, we'll corrupt its input data randomly with noise before each epoch.\n",
        "\n",
        "There are many strategies to introduce noise: adding gaussian white noise, occluding with random black rectangles, etc. We will add gaussian white noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:52:04.861818Z",
          "start_time": "2018-01-04T16:52:04.856134Z"
        },
        "collapsed": true,
        "id": "IGiOcti81x3Y"
      },
      "source": [
        "def apply_gaussian_noise(X,sigma=0.1):\n",
        "    \"\"\"\n",
        "    adds noise from standard normal distribution with standard deviation sigma\n",
        "    :param X: image tensor of shape [batch,height,width,3]\n",
        "    Returns X + noise.\n",
        "    \"\"\"\n",
        "    noise = ### YOUR CODE HERE ###\n",
        "    return X + noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:52:06.264119Z",
          "start_time": "2018-01-04T16:52:06.223714Z"
        },
        "collapsed": true,
        "id": "qlmNdZTp1x3Y"
      },
      "source": [
        "# noise tests\n",
        "theoretical_std = (X_train[:100].std()**2 + 0.5**2)**.5\n",
        "our_std = apply_gaussian_noise(X_train[:100],sigma=0.5).std()\n",
        "assert abs(theoretical_std - our_std) < 0.01, \"Standard deviation does not match it's required value. Make sure you use sigma as std.\"\n",
        "assert abs(apply_gaussian_noise(X_train[:100],sigma=0.5).mean() - X_train[:100].mean()) < 0.01, \"Mean has changed. Please add zero-mean noise\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:52:08.220681Z",
          "start_time": "2018-01-04T16:52:07.737460Z"
        },
        "collapsed": true,
        "id": "VYMGMgzZ1x3Y"
      },
      "source": [
        "# test different noise scales\n",
        "plt.subplot(1,4,1)\n",
        "show_image(X_train[0])\n",
        "plt.subplot(1,4,2)\n",
        "show_image(apply_gaussian_noise(X_train[:1],sigma=0.01)[0])\n",
        "plt.subplot(1,4,3)\n",
        "show_image(apply_gaussian_noise(X_train[:1],sigma=0.1)[0])\n",
        "plt.subplot(1,4,4)\n",
        "show_image(apply_gaussian_noise(X_train[:1],sigma=0.5)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSc9Ppu81x3Z"
      },
      "source": [
        "Training will take **1 hour**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:02.667408Z",
          "start_time": "2018-01-04T16:52:31.853874Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "D_LoT5iR1x3Z"
      },
      "source": [
        "s = reset_tf_session()\n",
        "\n",
        "# we use bigger code size here for better quality\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=512)\n",
        "assert encoder.output_shape[1:]==(512,), \"encoder must output a code of required size\"\n",
        "\n",
        "inp = L.Input(IMG_SHAPE)\n",
        "code = encoder(inp)\n",
        "reconstruction = decoder(code)\n",
        "\n",
        "autoencoder = keras.models.Model(inp, reconstruction)\n",
        "autoencoder.compile('adamax', 'mse')\n",
        "\n",
        "for i in range(25):\n",
        "    print(\"Epoch %i/25, Generating corrupted samples...\"%(i+1))\n",
        "    X_train_noise = apply_gaussian_noise(X_train)\n",
        "    X_test_noise = apply_gaussian_noise(X_test)\n",
        "    \n",
        "    # we continue to train our model with new noise-augmented data\n",
        "    autoencoder.fit(x=X_train_noise, y=X_train, epochs=1,\n",
        "                    validation_data=[X_test_noise, X_test],\n",
        "                    callbacks=[keras_utils.TqdmProgressCallback()],\n",
        "                    verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:09.059164Z",
          "start_time": "2018-01-04T16:56:06.987995Z"
        },
        "collapsed": true,
        "scrolled": true,
        "id": "V-T4gZnx1x3Z"
      },
      "source": [
        "X_test_noise = apply_gaussian_noise(X_test)\n",
        "denoising_mse = autoencoder.evaluate(X_test_noise, X_test, verbose=0)\n",
        "print(\"Denoising MSE:\", denoising_mse)\n",
        "for i in range(5):\n",
        "    img = X_test_noise[i]\n",
        "    visualize(img,encoder,decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duOewoDa1x3Z"
      },
      "source": [
        "# Optional: Image retrieval with autoencoders\n",
        "\n",
        "So we've just trained a network that converts image into itself imperfectly. This task is not that useful in and of itself, but it has a number of awesome side-effects. Let's see them in action.\n",
        "\n",
        "First thing we can do is image retrieval aka image search. We will give it an image and find similar images in latent space:\n",
        "\n",
        "<img src=\"https://github.com/PhiDung-hub/intro-to-dl/blob/master/week4/images/similar_images.jpg?raw=1\" style=\"width:60%\">\n",
        "\n",
        "To speed up retrieval process, one should use Locality Sensitive Hashing on top of encoded vectors. This [technique](https://erikbern.com/2015/07/04/benchmark-of-approximate-nearest-neighbor-libraries.html) can narrow down the potential nearest neighbours of our image in latent space (encoder code). We will caclulate nearest neighbours in brute force way for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:25.988163Z",
          "start_time": "2018-01-04T16:56:25.784071Z"
        },
        "collapsed": true,
        "id": "DbA5bNoZ1x3Z"
      },
      "source": [
        "# restore trained encoder weights\n",
        "s = reset_tf_session()\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
        "encoder.load_weights(\"encoder.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:30.368727Z",
          "start_time": "2018-01-04T16:56:29.246409Z"
        },
        "collapsed": true,
        "id": "sOZNYH-J1x3Z"
      },
      "source": [
        "images = X_train\n",
        "codes = ### YOUR CODE HERE: encode all images ###\n",
        "assert len(codes) == len(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:39.396176Z",
          "start_time": "2018-01-04T16:56:39.370156Z"
        },
        "collapsed": true,
        "id": "u0_Gt12B1x3Z"
      },
      "source": [
        "from sklearn.neighbors.unsupervised import NearestNeighbors\n",
        "nei_clf = NearestNeighbors(metric=\"euclidean\")\n",
        "nei_clf.fit(codes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:42.213214Z",
          "start_time": "2018-01-04T16:56:42.206902Z"
        },
        "collapsed": true,
        "id": "uHv467DY1x3Z"
      },
      "source": [
        "def get_similar(image, n_neighbors=5):\n",
        "    assert image.ndim==3,\"image must be [batch,height,width,3]\"\n",
        "\n",
        "    code = encoder.predict(image[None])\n",
        "    \n",
        "    (distances,),(idx,) = nei_clf.kneighbors(code,n_neighbors=n_neighbors)\n",
        "    \n",
        "    return distances,images[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:44.008658Z",
          "start_time": "2018-01-04T16:56:43.997658Z"
        },
        "collapsed": true,
        "id": "tDoYpPaN1x3a"
      },
      "source": [
        "def show_similar(image):\n",
        "    \n",
        "    distances,neighbors = get_similar(image,n_neighbors=3)\n",
        "    \n",
        "    plt.figure(figsize=[8,7])\n",
        "    plt.subplot(1,4,1)\n",
        "    show_image(image)\n",
        "    plt.title(\"Original image\")\n",
        "    \n",
        "    for i in range(3):\n",
        "        plt.subplot(1,4,i+2)\n",
        "        show_image(neighbors[i])\n",
        "        plt.title(\"Dist=%.3f\"%distances[i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaJTETjK1x3a"
      },
      "source": [
        "Cherry-picked examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:57:31.768260Z",
          "start_time": "2018-01-04T16:57:31.240174Z"
        },
        "collapsed": true,
        "id": "mJgAmx4k1x3a"
      },
      "source": [
        "# smiles\n",
        "show_similar(X_test[247])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:50.828404Z",
          "start_time": "2018-01-04T16:56:50.462822Z"
        },
        "collapsed": true,
        "id": "DhdN2dib1x3a"
      },
      "source": [
        "# ethnicity\n",
        "show_similar(X_test[56])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:56:52.939288Z",
          "start_time": "2018-01-04T16:56:52.576097Z"
        },
        "collapsed": true,
        "scrolled": false,
        "id": "BiHg8M6F1x3a"
      },
      "source": [
        "# glasses\n",
        "show_similar(X_test[63])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-B8NqXfs1x3a"
      },
      "source": [
        "# Optional: Cheap image morphing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vj2IKmk1x3a"
      },
      "source": [
        "We can take linear combinations of image codes to produce new images with decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:57:58.378044Z",
          "start_time": "2018-01-04T16:57:58.145544Z"
        },
        "collapsed": true,
        "id": "OwmrMkWa1x3a"
      },
      "source": [
        "# restore trained encoder weights\n",
        "s = reset_tf_session()\n",
        "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
        "encoder.load_weights(\"encoder.h5\")\n",
        "decoder.load_weights(\"decoder.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-01-04T16:58:03.396368Z",
          "start_time": "2018-01-04T16:58:00.359973Z"
        },
        "collapsed": true,
        "id": "eEBqrOfZ1x3b"
      },
      "source": [
        "for _ in range(5):\n",
        "    image1,image2 = X_test[np.random.randint(0,len(X_test),size=2)]\n",
        "\n",
        "    code1, code2 = encoder.predict(np.stack([image1, image2]))\n",
        "\n",
        "    plt.figure(figsize=[10,4])\n",
        "    for i,a in enumerate(np.linspace(0,1,num=7)):\n",
        "\n",
        "        output_code = code1*(1-a) + code2*(a)\n",
        "        output_image = decoder.predict(output_code[None])[0]\n",
        "\n",
        "        plt.subplot(1,7,i+1)\n",
        "        show_image(output_image)\n",
        "        plt.title(\"a=%.2f\"%a)\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "n6X0DOG_1x3b"
      },
      "source": [
        "That's it!\n",
        "\n",
        "Of course there's a lot more you can do with autoencoders.\n",
        "\n",
        "If you want to generate images from scratch, however, we recommend you our honor track on Generative Adversarial Networks or GANs."
      ]
    }
  ]
}